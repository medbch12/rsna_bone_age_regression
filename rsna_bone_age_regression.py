# -*- coding: utf-8 -*-
"""rsna_bone_age_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i8ivoLypMqKLqIODO9lDDvahBtvd5Xs4
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import os
import timeit
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

np.random.seed(12049)

def get_plot_loss(model, model_name):
    fig = plt.figure()
    plt.subplot(2, 1, 1)
    plt.plot(model.history.history["loss"])
    plt.plot(model.history.history["val_loss"])
    plt.title(f"{model_name} \n\n Model Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(["Train", "Valid"], loc="upper right")

    plt.subplot(2, 1, 2)
    plt.plot(model.history.history["mae"])
    plt.plot(model.history.history["val_mae"])
    plt.title("Model Mean Absolute Error")
    plt.ylabel("Mean Absolute Error")
    plt.xlabel("Epoch")
    plt.legend(["Train", "Valid"], loc="upper right")

    plt.tight_layout()
    plt.show()


def get_evaluate(data, name, model):
    score_model = model.evaluate(data, verbose=1)
    print(f"{name} loss: {score_model:.2f}")


def get_predict(data, model):
    predict_model = model.predict(data)
    return predict_model


def get_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)

    print(f"Mean Absolute Error - {model_name}: {mae:.2f}")
    print(f"Mean Squared Error - {model_name}: {mse:.2f}")

# Load data
base_dir = "/kaggle/input/rsna-bone-age"
train_path = os.path.join(base_dir, 'boneage-training-dataset')
test_path = os.path.join(base_dir, 'boneage-test-dataset')

model_name = "ResNet50_regression"
target_size = (224, 224)
epochs = 100
batch_size = 32
img_shape = (224, 224, 3)

aug_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = aug_datagen.flow_from_directory(
    train_path, target_size=target_size, batch_size=batch_size, shuffle=True
)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1.0 / 255
)

test_generator = test_datagen.flow_from_directory(
    test_path, target_size=target_size, batch_size=batch_size, shuffle=False
)

early = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0.01, patience=8, restore_best_weights=True
)

plateau = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='loss', factor=0.1, min_delta=0.01, min_lr=1e-10, patience=4, mode='auto'
)

# Load pre-trained ResNet50 model
base_model = tf.keras.applications.ResNet50(
    input_shape=img_shape, include_top=False, weights=None
)
weights_path = '/kaggle/input/resnet50-weights-h5/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'
base_model.load_weights(weights_path)

for layer in base_model.layers:
    layer.trainable = True

model_regression = tf.keras.models.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='linear')
])
model_regression.summary()

model_regression.compile(
    optimizer='adam', loss='mean_squared_error', metrics=['mae']
)
start_time = timeit.default_timer()
history = model_regression.fit(
    train_generator, epochs=epochs, batch_size=batch_size, callbacks=[early, plateau],
    validation_data=test_generator, verbose=1
)

stop_time = timeit.default_timer()

execution_time = (stop_time - start_time) / 60.0
print(f"Model {model_name} fine tuning executed in {execution_time:.2f} minutes")

# Plot loss and mean absolute error
def get_plot_loss(model, model_name):
    plt.plot(model.history.history["loss"])
    plt.plot(model.history.history["val_loss"])
    plt.title(f"{model_name} \n\n Model Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(["Train", "Valid"], loc="upper right")

    plt.show()

get_plot_loss(history, model_name)

# Evaluate the model
def get_evaluate(data, name, model):
    score_model = model.evaluate(data, verbose=1)
    print(f"{name} loss: {score_model:.2f}")

get_evaluate(test_generator, "Test", model_regression)

def get_predict(data, model):
    predict_model = model.predict(data)
    return predict_model

y_pred = get_predict(test_generator, model_regression)

def get_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)

    print(f"Mean Absolute Error - {model_name}: {mae:.2f}")
    print(f"Mean Squared Error - {model_name}: {mse:.2f}")

get_metrics(test_generator.labels, y_pred, model_name)